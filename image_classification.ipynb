{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "measured-premises",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (2.4.1)\n",
      "Requirement already satisfied: keras in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (2.4.3)\n",
      "Requirement already satisfied: Pillow in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (8.2.0)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.3.4-cp36-cp36m-manylinux1_x86_64.whl (11.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.5 MB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting seaborn\n",
      "  Downloading seaborn-0.11.1-py3-none-any.whl (285 kB)\n",
      "\u001b[K     |████████████████████████████████| 285 kB 56.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from tensorflow) (3.15.8)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from tensorflow) (0.12.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow) (1.30.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow) (56.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (4.0.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from keras) (1.5.4)\n",
      "Requirement already satisfied: pyyaml in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from keras) (5.4.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from matplotlib) (2.8.1)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 66.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting pandas>=0.23\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.5 MB 42.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz>=2017.2\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 510 kB 29.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.1)\n",
      "Installing collected packages: pytz, kiwisolver, cycler, pandas, matplotlib, seaborn\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.3.4 pandas-1.1.5 pytz-2021.1 seaborn-0.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow keras Pillow matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dense-forestry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "rough-today",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-advocacy",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "brilliant-windows",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/training'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3052d2c99bff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bilinear\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearning/lib/python3.6/site-packages/tensorflow/python/keras/preprocessing/image_dataset.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links)\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m       follow_links=follow_links)\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlabel_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearning/lib/python3.6/site-packages/tensorflow/python/keras/preprocessing/dataset_utils.py\u001b[0m in \u001b[0;36mindex_directory\u001b[0;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001b[0m\n\u001b[1;32m     63\u001b[0m   \"\"\"\n\u001b[1;32m     64\u001b[0m   \u001b[0minferred_class_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m       \u001b[0minferred_class_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/training'"
     ]
    }
   ],
   "source": [
    "images = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'dataset/training',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    ")\n",
    "print(images.__dict__.keys())\n",
    "print(images._structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "forty-collar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15951 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory('dataset/train',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "#print(training_set.__dict__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "digital-welcome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='count'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(training_set.classes)\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "sns.countplot(training_set.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "spatial-exclusive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('dataset/test',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-alert",
   "metadata": {},
   "source": [
    "####  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "amino-buying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joaoegewarth/.virtualenvs/deeplearning/lib/python3.6/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='count'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(test_set.classes)\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "sns.countplot(test_set.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "finished-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "conscious-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "preceding-study",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " 54/499 [==>...........................] - ETA: 7:29 - loss: 0.4461 - accuracy: 0.8114"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-894200829115>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/deeplearning/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearning/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearning/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearning/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearning/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearning/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.virtualenvs/deeplearning/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-disclaimer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
